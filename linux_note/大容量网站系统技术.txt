  
  LVS
  Heartbeat
  corosync
  cman+rgmanager
  keepalived
  
  
  第一个场景普通的WEB网站
  一台WEB服务器,有2个CPU,每个CPU有4个物理核心,相当与8核,16G内存.早起站点都是基本都是这样的配置.网站都是由小到大一步一步迭代而来的,没有人能够一开始就能设计一个架构能够通用,为什么不能?第一成本高,一开始就设计很多这样的组件,那样的组件,业务需求没有到达这个层次的时候就用,肯定会造成财务费用上的负担.第二人力消耗,布置这么多的物理资源,需不需要人员去维护.总不能说硬件买回来就丢在哪里不管了!该怎么管理?这些都需要人员去跟进.所以最早都是用最少的物理资源配置.LAMP或者LNMP.
  
  万一我们的网站受欢迎了,用户越来越多.假如说的网站大概承载1000个并发,(通常我们的注册用户大于在线用户,而在线用户大于并发用户.虽然我们服务器随时都有用户在访问,页面返回给用户以后,用户会需要很多时间去浏览页面,2分钟,5分钟,10分钟以后再发起一个新的请求.所以并发量其实不会很高.)再假如说1000个并发响应的时间是2S,当我们到达1500个并发的时候,服务器响应时间可能会上升到5S,那当我们并发达到1800个的时候,有可能构建响应就需要10S.
  这样下来,显然我们服务器能够承载1800个并发的访问量,但这时候的用户体验很差,所以我们应该将服务器状态调整到一个用户体验较好的情况.而且服务器不光要响应用户的请求,服务器需要进行其它事务进程.用户请求来了,web程序需不需要去访问图片资源?需不需要去对用户请求进行处理?处理之后需不需要和数据库交互...?还有,web程序要不要记录日志?服务器需不需要记录进程日志?监控程序要不要对这些行为进行统计?所以为了整个系统的稳定正常,我们不能让网站运行在一个响应1500个并发以上的情况下.
  但是到了这个时候我们的并发量达到了1800个,我们应该怎么做?
  这时候要做扩展,向上扩展(Scale up),提升CPU,内存,硬盘等硬件的性能,缺点,当服务器性能达到极致,配件用到最好的,通常硬件升级价格很昂贵.有些入门服务器1两万,但是有些服务器几十万一台.不可能无限堆叠CPU,内存等硬件,而且服务器就算解决了,网络呢?一个服务器能承受几十万,几百万的并发量,到哪里去找这么大的带宽?所以提高服务器性能这种扩展获得的性价比不是线性的.通俗的说,把服务器能力提升1倍,资金投入可能要多好几倍.代价也会越来越大.而且向上扩展是有上限的.没有办法实现facebook,google,qq这样的网站跑在一台机器上的.所以最好的方式是向外扩展
  
  第二个场景
  向外扩展(Scale out):提供同样功能的多台服务器.这个时候就要考虑如何让多台服务器良好的共同工作.比如一台服务器能容纳1000个,两台服务器容纳2000个
  当我们用户请求到达的时候如何让第二台服务器去响应用户的请求呢?最简单的方式,DNS调度,也就是两个A记录指向同一个域名, 但是如果是企业,学校等局域网,同一个运营商的用户都可能访问到同一个服务器,极端情况下可能一台有几千个并发,另一个只有几个并发用户.
  所以我们就在web前面加调度器(负载均衡),所有用户请求都到达调度器,调度器根据某种规则来分配用户.同时把WEB和数据库剥离,保证每个用户访问的数据都是一致的. 随着前端WEB服务器的增加,数据库的查询能力有限.这时候我们又进行读写分离,这个时候我们又需要考虑,怎么调度,数据库的读怎么读,写怎么写.要么交给web程序来解决.要么在数据库前面增加调度器(数据库的负载均衡).这时候好像完美解决了问题,实现这一系列性能瓶颈的解决方案,我们称之为扩容.
  但是带来新的问题,如果调度器或者其中一台服务器坏了怎么办?如果调度器坏了,整个系统就无法响应,就造成了单点故障,显然是致命的.我们知道硬件损坏(内存,CPU,硬盘),停电,网络波动等问题很常见,假如一台服务器出现故障几率是1%,我们有10台服务器,整个系统的故障率就提升到10%,(如何一台服务器出现故障都可能导致整个系统无法使用.),当我们服务器达到100台呢?服务器越多出现问题的几率就越高(阿里,腾讯,google,几万台机器每天坏个10台,8台机器很正常).所谓的高可用性(HA).平均无故障时间/(平均无故障时间+平均修复时间)=高可用性
  比如说HA为95%按一年来算一年当中有接近19天的故障时间
  HA为99%一年中有大概有4天的故障时间
  HA为99.9%一年中有10个小时的故障时间10个小时
  99.999%相当于一个系统一年中离线时间不能超过几秒钟(一个服务器重启一次都不止几秒钟)?所以高可用的提升,对系统运行稳定性提升是有极大提升.
  所以我们就用提供备用服务器的方式来解决这样的问题,高可用集群.备用服务器运发送数据(heartbeat心跳检测)来观察主服务器,一旦发现主服务器故障就将自动接手坏掉服务器的任务,并将IP等关键配置切换过来.并提醒管理人员主服务器故障,需要更换或修理.很多时候为了节约资源.我们的备用机器性能不如主服务器.在我们修理好以后需要切换回来.或者通过高可用策略自动切换回来.
  所以后台数据库服务器也要做类似的高可用
  如果后端web服务器坏了怎么办?调度器会调度了很多用户到坏的服务器上.所以调度器还需要对后端的WEB服务器进行健康状态检测,一旦WEB服务器不在线就停止对他进行用户的分配.修复后重新进行分配.
  但是现在又有新的问题.例如电商站点,会有很多用户浏览商品后会将物品添加到购物车中去,因为http协议是无状态的.所以一刷新,购物车就清空了,这时候客户端用cookie来保存自己的信息,服务器就用与cookie对应的session来将用户的信息保存到服务器.同时有可能每个WEB所保存的会话信息session不一致,如果用户被分配到不同的服务器上,或者其中一个服务器挂掉,就会造成session丢失,这时候我们就需要一种机制保持session,解决方案就有三种,绑定用户,同一个用户始终绑定到一个服务器(但是破坏均衡,也不能解决服务器故障的问题.).session集群,把每个服务器的ssension同步到每一个web服务器的session库当中(带来额外网络带宽消耗,和服务器的IO提升.).ssension服务器,把每个服务器的保存到指定的session服务器.(还是有单点故障,也存在网络同步的问题)

  分布式文件系统.对于电商站点,每个商品都有很多图片,如果都保存到本地.可能造成每个服务器的资源不一致,而且本地磁盘的容量有限,这时就需要用到共享存储.共享存储也存在新的问题,在大规模并发的时候,有存在网络并发和磁盘IO性能瓶颈,如同web集群一样,我们也要做分流调度,用多个服务器做图片存储集群,每个服务器存储不同的图片,通过API的调度提供给前端WEB使用.不同的图片请求会分发到不同的服务器上,既提高了网络带宽的容纳能力,也减轻了磁盘IO的负载(例如一个服务器提供1T空间,100M带宽,10个服务器组成的集群就有10T空间1000M带宽.)
  28法则,一个网站的访问,很有可能用户访问的都是20%的热点信息,甚至比例更高,比如说新闻网站,访问量最高的都是一些热点新闻,很多新闻都没几个人看,再如电商网站,很大一部分商品上架几个月几年都无人问津.
  
  电商网站的数据库优化,
  数据库接收到WEB服务器发来的用户请求,就涉及到增删查改,是不是拿到数据我们就把他写进去?还涉及到数据检查,符不符合数据规范,操作是否具有权限.还有建立索引.
  用户搜索是针对某些关键词进行全表或全库的遍历,对相关的数据都要进行比对.假如一个搜索所花的时间需要10S,在这10S当中新的请求来了,就只能进行等待,包括其它对数据库的增删查改都必须等待.这样是不符合实际需求,所以我们就需要对数据库的数据做索引,简单通俗的来说索引就对某类数据集合的地址映射.这时候就需要把数据库所有数据抽取出来和WEB做关联建立索引.有涉及到存储,处理和建立索引.而且数据是永远变化的,索引也的根据数据变化不停在新增和修改.
  
  消息队列的问题,假如电商网站遇到某个场景,大量商家上架产品,有图片和数据,图片存分布式文件系统,数据存储到数据库,但是这个过程有快又慢,而我们必须在所有数据图片都存储完成以后才能告诉用户你的信息已录入成功.那假如说,需要20秒才能完成,这个时候我们就需要其它的机制来暂存收到的信息,然后在数据存储完成以后提示用户成功没有成功,不然所有的用户都必须等前一个用户处理完成才能进行下一个用户的处理.比如说提示,你的商品已上传成功,请稍后刷新页面.当然发展到这种规模的时候,我们需要对网站进行切割,按功能业务划分成不同功能子系统.做搜索集群,商户集群,支付集群,
  
  日志问题,用户访问信息的统计,每个资源被访问都会产生日志.还是前面说的问题,收集服务器的网络带宽和磁盘IO,日志集群分布式存储加分布式处理.
  缓存问题,实时读写,数据持久存储,分布式.比如说购物车的存储,这些数据不需要写入数据库,但是又需要持续一段时间,而且是要求实时读写的.NOSQL技术
  
  云:
  某一台物理机上硬件坏了,我们需要进行更换修复.这个过程需要一定的时间.这时候就需要用到云技术,我们的物理机不运行特定的服务(WEB,数据库,分布式存储,缓存系统等),而是运行虚拟的操作系统,将我们的网站各种集群架设在这样的云上.即使某一台物理机出现故障,我们在另外的虚拟机上重新启动故障机所运行的服务.这样做的好处,第一可以按需定制,比如说物理机有8G内存,300G存储空间,而我们的一个服务只需要2G内存,20G存储,又不得不单独运行在一个操作系统上(和其它服务有冲突等).这个时候虚拟化就可以节省资源,我们把这个单独的服务运行在一个虚拟机上,同时剩下的资源又可以打开一个虚拟机提供其它的服务.这样就把一个个硬件属性虚拟出来可以做一个弹性的分配.即使物理机出现故障,也可以通过技术手段将服务很快迁移到其它的虚拟机上.现在的虚拟化技术已经可以做到服务不终止的实时迁移,比如说阿里云,有可能我们现在使用的网站服务器内存坏了,我们的网站服务器服务根本感觉不到中断.
  
  
  CDN,网络缓存,将某些不常变化而又经常访问的图片或其它静态资源放在不同服务商缓存服务器(浏览商品页面).当请求动态内容需要程序处理的内容就访问后端的真正服务器(上架商品,用户交流,交易支付等)
  
  抢购活动,某一天做促销.某一天涌入网站5倍,10倍的用户,用一组静态服务器.根据测试能够响应1000并发动态内容的服务器能够响应10倍甚至更高的静态内容.当服务器不能承受压力的时候,将一部分用户切换到静态服务器上去,(小米的抢购模式,一旦服务器崩溃,就给用户提供一个静态的提示页面)降级服务,保障能够响应的用户,继续提供服务.而不至于整个网站的崩溃
  
  自动化,自动化的好处,很多人觉得是效率.而我感觉自动化最好的地方是避免了人为错误. 比如编写一个程序让他一天都算1+1=几,这个不光是效率问题一天可以算多少次,而是永远不会算错. 运维追求的是稳定,现在开发要求的敏捷开发,快速迭代.会对运维造成影响,而且每一次代码上线都会给运维带来风险,修复老BUG造成新BUG,新功能不完善造成服务崩溃等.所以运维和开发的目标是背离的.当我们的服务器多了,服务器的内容怎么做到同步. 同时更新可能造成无法挽回的后果.狭义的来说,机器是用于不会出错,出错的原因始终是人,比如软件代码问题,人不写错代码,机器不可能出问题,在比如错,API或引用的库错,这个人编写的.程序只是按照人的意旨去处理数据.(而且很多是人的思维无法预见的)就算是硬件故障,狭义的理解,硬件还不是人生产的.自动化以后,所有高危工作交给机器处理,只要指令不存在bug或错误,就很大程度避免了生产事故.当然自动化不当使用的后果也是非常严重和无法挽回的.
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  
  